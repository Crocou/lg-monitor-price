# crawl_scroll_zip65760.py
"""
Amazon.de ë² ìŠ¤íŠ¸ì…€ëŸ¬ â–¸ Monitors 1~100ìœ„
- LG ëª¨ë‹ˆí„° í•„í„°, ê°€ê²©Â·ìˆœìœ„Â·ë³€ë™ ê¸°ë¡ (ìŠ¤í¬ë¡¤ í¬í•¨)
- â˜… ë°°ì†¡ì§€(ìš°í¸ë²ˆí˜¸) 65760 ê³ ì •
"""

import sys, os, re, json, base64, datetime, time, logging
import requests, pandas as pd, gspread, pytz
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException
from gspread_formatting import format_cell_ranges, CellFormat, TextFormat, Color
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException


# â”€â”€â”€ 0. ë¡œê¹… ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("crawl_cards.log", encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logging.info("ğŸ” LG ëª¨ë‹ˆí„° í¬ë¡¤ëŸ¬ ì‹œì‘")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Selenium ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_driver():
    service = None
    opt = webdriver.ChromeOptions()
    opt.add_argument("--headless=new")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument("--window-size=1280,4000")
    opt.add_argument("--lang=de-DE")
    opt.add_argument(
        "user-agent=Mozilla/5.0 (X11; Linux x86_64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/126.0 Safari/537.36"
    )
    return webdriver.Chrome(service=service, options=opt)

# â˜… 1-A. ìš°í¸ë²ˆí˜¸ ê³ ì • í•¨ìˆ˜ --------------------------------------------------------
def set_zip(driver, zip_code="65760"):
    payload = (
        f"locationType=LOCATION_INPUT&zipCode={zip_code}"
        "&storeContext=computers&deviceType=web&pageType=Detail&actionSource=glow"
    )
    script = """
        const zip = arguments[0];
        const body = arguments[1];
        const done = arguments[2];

        fetch("https://www.amazon.de/gp/delivery/ajax/address-change.html", {
            method: "POST",
            headers: {
                "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
                "X-Requested-With": "XMLHttpRequest"
            },
            body: body
        })
        .then(() => done())
        .catch(() => done());
    """
    driver.execute_async_script(script, zip_code, payload)
    driver.refresh()
    time.sleep(1)
    driver.add_cookie({"name": "deliveryZip", "value": zip_code})

BASE_URL = "https://www.amazon.de/gp/bestsellers/computers/429868031/"  # pg=1|2
CARD_SEL = (
    "li.zg-no-numbers"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. í˜ì´ì§€ì—ì„œ ì¹´ë“œ ê°€ì ¸ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_URL = "https://www.amazon.de/gp/bestsellers/computers/429868031/"
CARD_SEL = "li.zg-no-numbers"


def money_to_float(txt: str):
    """'â‚¬196,79' ë˜ëŠ” 'â‚¬196.79' â†’ 196.79 (float)"""
    if not txt:
        return None
    # NBSPÂ·ì¢ì€ê³µë°± ì œê±°
    txt = txt.replace("\u00a0", "").replace("\u202f", "")
    # í†µí™”Â·ë¬¸ì ì œê±°
    txt_clean = re.sub(r"[^\d,\.]", "", txt)

    # ì†Œìˆ˜ êµ¬ë¶„ì ê°ì§€
    if "," in txt_clean and "." in txt_clean:
        # ë§ˆì§€ë§‰ êµ¬ë¶„ìë¥¼ ì†Œìˆ˜ì ìœ¼ë¡œ ê°„ì£¼
        if txt_clean.rfind(",") > txt_clean.rfind("."):
            txt_clean = txt_clean.replace(".", "").replace(",", ".")
        else:
            txt_clean = txt_clean.replace(",", "")
    elif "," in txt_clean and "." not in txt_clean:
        txt_clean = txt_clean.replace(",", ".")
    else:
        txt_clean = txt_clean  # ì´ë¯¸ '.'ë§Œ ìˆê±°ë‚˜ êµ¬ë¶„ì ì—†ìŒ

    try:
        return float(txt_clean)
    except ValueError:
        logging.warning(f"ê°€ê²© ë³€í™˜ ì‹¤íŒ¨: {txt}")
        return None

def fetch_cards_and_parse(page: int, driver):
    parsed_items = []
    url = BASE_URL if page == 1 else f"{BASE_URL}?pg={page}"
    logging.info("â–¶ï¸  ìš”ì²­ URL (page %d): %s", page, url)
    driver.get(url)

    # â”€â”€ ë°°ì†¡ì§€Â·í†µí™” ì¿ í‚¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    driver.add_cookie({"name": "lc-main", "value": "de_DE"})
    driver.add_cookie({"name": "i18n-prefs", "value": "EUR"})
    # â‘  ë°°ì†¡ì§€ ì¿ í‚¤ê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì£¼ì…
    if not driver.get_cookie("deliveryZip"):
        driver.add_cookie({"name": "deliveryZip", "value": "65760"})
    driver.refresh()
    logging.info("ì¿ í‚¤ í™•ì¸ â†’ deliveryZip=%s", driver.get_cookie("deliveryZip"))

    # â”€â”€â”€ â˜… ìµœì†Œ í•œ ì¥ì´ë¼ë„ ëœ° ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 20ì´ˆ) â”€â”€â”€
    try:
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, CARD_SEL))
        )
    except TimeoutException:
        logging.error(f"â›” page {page}: ì¹´ë“œê°€ í•œ ì¥ë„ ì•ˆ ëœ¸ â€” íƒ€ì„ì•„ì›ƒ")
        return []                # ë°”ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜í•´ ë‹¤ìŒ í˜ì´ì§€ ì‹œë„

    # â”€â”€â”€ ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ì¶”ê°€ ì¹´ë“œ ë¡œë”© â”€â”€â”€
    SCROLL_PAUSE = 10
    MAX_WAIT = 60                # ìŠ¤í¬ë¡¤ ìµœëŒ€ ëŒ€ê¸°(ì´ˆ) â€” í•„ìš”ì— ë§ê²Œ ì¡°ì •
    start = time.time()
    last = 0
    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE)

        cards = driver.find_elements(By.CSS_SELECTOR, CARD_SEL)
        now = len(cards)

        # page 1ì´ë¼ë©´ 50ê°œ ê½‰ ì°° ë•Œê¹Œì§€ ì‹œë„ (í•„ìš” ì—†ìœ¼ë©´ ì¡°ê±´ ì‚­ì œ)
        if page == 1 and now < 50 and time.time() - start < MAX_WAIT:
            continue

        if now == last or time.time() - start >= MAX_WAIT:
            break
        last = now

    logging.info(f"âœ… page {page} ì¹´ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {len(cards)}ê°œ")


    for idx, card in enumerate(cards, start=1):
        # â”€â”€â”€â”€â”€ ë­í¬ â”€â”€â”€â”€â”€
        try:
            rank_el = card.find_element(By.XPATH, './/span[contains(@class,"zg-bdg-text")]')
            rank_text = rank_el.text.strip()
            rank = int(re.sub(r"\D", "", rank_text))  # "#1" â†’ "1"
        except (NoSuchElementException, ValueError, StaleElementReferenceException):
            logging.warning(f"[{idx}] ë­í¬ ì¶”ì¶œ ì‹¤íŒ¨ â†’ ê±´ë„ˆëœ€")
            continue

        # â”€â”€â”€â”€â”€ ì œëª© â”€â”€â”€â”€â”€
        try:
            try:
                title = card.find_element(By.XPATH, './/div[contains(@class,"_cDEzb_p13n-sc-css-line-clamp-2_EWgCb")]').text.strip()
            except NoSuchElementException:
                title = card.find_element(By.XPATH, './/img[@alt]').get_attribute("alt").strip()
        except Exception:
            title = ""

        # NBSP ëŒ€ì²´ í›„ LG ì—¬ë¶€ ì²´í¬
        title_norm = title.replace("\u00a0", " ").replace("\u202f", " ")
        lg_match = bool(re.search(r"\bLG\b", title_norm, re.I))

        # â”€â”€â”€â”€â”€ ê°€ê²© â”€â”€â”€â”€â”€
        price_raw = ""
        # â‘¡ 1ìˆœìœ„: ì¹´ë“œ ì•ˆì˜ â€˜ì˜¤ëŠ˜ ê°€ê²©â€™
        try:
            price_raw = card.find_element(
                By.CSS_SELECTOR, 'span._cDEzb_p13n-sc-price_3mJ9Z'
            ).text.strip()
        except NoSuchElementException:
            pass

        # â‘¢ 2ìˆœìœ„: â€˜3 offers from â‚¬123â€™ í˜•íƒœ
        if not price_raw:
            try:
                offer_txt = card.find_element(
                    By.CSS_SELECTOR, 'span.a-color-secondary'
                ).text.strip()          # ì˜ˆ: "3 offers from â‚¬123.45"
                m = re.search(r'â‚¬[\d\.,]+', offer_txt)
                if m:
                    price_raw = m.group(0)   # "â‚¬123.45" ì¶”ì¶œ
            except NoSuchElementException:
                pass

        price_val = money_to_float(price_raw)

        # â”€â”€â”€â”€â”€ ë§í¬/ASIN â”€â”€â”€â”€â”€
        try:
            a = card.find_element(By.XPATH, './/a[contains(@href,"/dp/")]')
            href = a.get_attribute("href")
            link = href.split("?", 1)[0] if href.startswith("http") else "https://www.amazon.de" + href.split("?", 1)[0]
            asin = re.search(r"/dp/([A-Z0-9]{10})", link).group(1)
        except Exception:
            logging.warning(f"[{idx}] ë§í¬/ASIN ì¶”ì¶œ ì‹¤íŒ¨ â†’ ê±´ë„ˆëœ€")
            continue

        # â”€â”€â”€â”€â”€ ë¡œê¹… ë° ê²°ê³¼ â”€â”€â”€â”€â”€
        card_info = {
            "rank": rank,
            "title": title,
            "price_text": price_raw,
            "price": price_val,
            "asin": asin,
            "url": link,
            "lg_match": lg_match,
        }
        logging.info(f"CARD_DATA {json.dumps(card_info, ensure_ascii=False)}")

        if lg_match:
            parsed_items.append({
                "asin": asin,
                "title": title,
                "url": link,
                "price": price_val,
                "rank": rank,
            })

    return parsed_items

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ìˆ˜ì§‘ ë° íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
driver = get_driver()
driver.get("https://www.amazon.de/")
set_zip(driver, "65760")

items = []
for pg in (1, 2):
    items += fetch_cards_and_parse(pg, driver)

driver.quit()
logging.info(f"LG ëª¨ë‹ˆí„° í•„í„° í›„ {len(items)}ê°œ ë‚¨ìŒ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. DataFrame ë° ë¹ˆ ê²°ê³¼ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cols = ["asin", "title", "url", "price", "rank"]
df_today = pd.DataFrame(items, columns=cols)

if df_today.empty:
    logging.info("LG ëª¨ë‹ˆí„° ì—†ìŒ â†’ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ìƒëµ")
    sys.exit(0)

df_today = df_today.sort_values("rank").reset_index(drop=True)

kst = pytz.timezone("Asia/Seoul")
df_today["date"] = datetime.datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Google Sheet ê¸°ë¡ (ì´í•˜ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
creds = Credentials.from_service_account_info(
    json.loads(base64.b64decode(os.environ["GCP_SA_BASE64"]).decode()),
    scopes=SCOPES,
)
gc = gspread.authorize(creds)
SHEET_ID = os.environ["SHEET_ID"]
sh = gc.open_by_key(SHEET_ID)

ws_hist = (
    sh.worksheet("History")
    if "History" in [w.title for w in sh.worksheets()]
    else sh.add_worksheet("History", rows=2000, cols=20)
)
ws_today = (
    sh.worksheet("Today")
    if "Today" in [w.title for w in sh.worksheets()]
    else sh.add_worksheet("Today", rows=100, cols=20)
)

try:
    prev = pd.DataFrame(ws_hist.get_all_records()).dropna()
except gspread.exceptions.APIError:
    prev = pd.DataFrame()

if not prev.empty and {"asin", "rank", "price", "date"} <= set(prev.columns):
    latest = (
        prev.sort_values("date")
        .groupby("asin", as_index=False)
        .last()[["asin", "rank", "price"]]
        .rename(columns={"rank": "rank_prev", "price": "price_prev"})
    )
    df_today = df_today.merge(latest, on="asin", how="left")
else:
    df_today["rank_prev"] = None
    df_today["price_prev"] = None

for col in ["price", "price_prev", "rank_prev"]:
    df_today[col] = pd.to_numeric(df_today[col], errors="coerce")

df_today["rank_delta_num"] = df_today["rank_prev"] - df_today["rank"]
df_today["price_delta_num"] = df_today["price"] - df_today["price_prev"]

def fmt(val, is_price=False):
    if pd.isna(val) or val == 0:
        return "-"
    arrow = "â–²" if val > 0 else "â–¼"
    return f"{arrow}{abs(val):.2f}" if is_price else f"{arrow}{abs(int(val))}"

df_today["rank_delta"] = df_today["rank_delta_num"].apply(fmt)
df_today["price_delta"] = df_today["price_delta_num"].apply(lambda x: fmt(x, True))

cols_out = [
    "asin",
    "title",
    "rank",
    "price",
    "url",
    "date",
    "rank_delta",
    "price_delta",
]
df_today = df_today[cols_out].fillna("")

# 6-B. ì‹œíŠ¸ ì“°ê¸°
if not ws_hist.get_all_values():
    ws_hist.append_row(cols_out, value_input_option="USER_ENTERED")
ws_hist.append_rows(df_today.values.tolist(), value_input_option="USER_ENTERED")

ws_today.clear()
ws_today.update([cols_out] + df_today.values.tolist(), value_input_option="USER_ENTERED")

# 6-C. â–²/â–¼ ì„œì‹
RED = Color(1, 0, 0)
BLUE = Color(0, 0, 1)
delta_cols = {"rank_delta": "G", "price_delta": "H"}
fmt_ranges = []
for i, row in df_today.iterrows():
    r = i + 2
    for col_name, col_letter in delta_cols.items():
        val = row[col_name]
        if isinstance(val, str) and val.startswith("â–²"):
            fmt_ranges.append(
                (f"{col_letter}{r}", CellFormat(textFormat=TextFormat(bold=True, foregroundColor=RED)))
            )
        elif isinstance(val, str) and val.startswith("â–¼"):
            fmt_ranges.append(
                (f"{col_letter}{r}", CellFormat(textFormat=TextFormat(bold=True, foregroundColor=BLUE)))
            )
if fmt_ranges:
    format_cell_ranges(ws_today, fmt_ranges)

logging.info("Google Sheet ì—…ë°ì´íŠ¸ ì™„ë£Œ â€” LG ëª¨ë‹ˆí„° %dê°œ", len(df_today))
print("âœ“ Google Sheet ì—…ë°ì´íŠ¸ ì™„ë£Œ â€” LG ëª¨ë‹ˆí„°", len(df_today))
