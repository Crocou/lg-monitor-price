import sys, os, re, json, base64, datetime, time, logging, pytz
import pandas as pd, gspread
from google.oauth2.service_account import Credentials
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from gspread_formatting import format_cell_ranges, CellFormat, TextFormat, Color

# â”€â”€â”€ 0. ë¡œê¹… ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("crawl_cards.log", encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logging.info("ğŸ” LG ëª¨ë‹ˆí„° í¬ë¡¤ëŸ¬ ì‹œì‘")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Selenium ë“œë¼ì´ë²„ ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_driver():
    service = None
    opt = webdriver.ChromeOptions()
    opt.add_argument("--headless=new")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument("--window-size=1280,4000")
    opt.add_argument("--lang=de-DE")
    opt.add_argument(
        "user-agent=Mozilla/5.0 (X11; Linux x86_64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/126.0 Safari/537.36"
    )
    return webdriver.Chrome(service=service, options=opt)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì¹´ë“œ í¬ë¡¤ë§ & íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_cards_and_parse(page: int, driver):
    parsed_items = []
    url = BASE_URL if page == 1 else f"{BASE_URL}?pg={page}"
    logging.info(f"â–¶ï¸  í˜ì´ì§€ {page} í¬ë¡¤ë§ ì‹œì‘ â€“ URL: {url}")
    driver.get(url)

    # í˜ì´ì§€ ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
    try:
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((
                By.XPATH,
                "//div[starts-with(@id,'CardInstance')]/div[2]//ol/li[contains(@class,'zg-no-numbers')]"
            ))
        )
    except TimeoutException:
        logging.warning(f"    í˜ì´ì§€ {page} ì´ˆë°˜ ë¡œë”© íƒ€ì„ì•„ì›ƒ, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤")

    # ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ì¶”ê°€ ë¡œë”© (ìµœëŒ€ MAX_WAIT ì´ˆ)
    SCROLL_PAUSE = 10
    MAX_WAIT = 60
    start = time.time()
    last_count = 0
    iteration = 0

    while True:
        iteration += 1
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE)

        cards = driver.find_elements(
            By.XPATH,
            "//div[starts-with(@id,'CardInstance')]/div[2]//ol/li[contains(@class,'zg-no-numbers')]"
        )
        now = len(cards)
        elapsed = int(time.time() - start)
        logging.info(f"   [ìŠ¤í¬ë¡¤ {iteration}] ë¡œë”©ëœ ì¹´ë“œ: {now}ê°œ, ê²½ê³¼: {elapsed}ì´ˆ")

        if now == last_count or elapsed >= MAX_WAIT:
            break
        last_count = now

    total = last_count or now
    logging.info(f"âœ… í˜ì´ì§€ {page} ì¹´ë“œ ìˆ˜ì§‘ ì™„ë£Œ: {total}ê°œ (ì´ ê²½ê³¼ {elapsed}ì´ˆ)")

    # ì¹´ë“œ íŒŒì‹±
    for idx, card in enumerate(cards, start=1):
        logging.info(f"  â–¶ ì¹´ë“œ [{idx}] íŒŒì‹± ì‹œì‘")
        # ë­í¬
        try:
            rank_text = card.find_element(
                By.XPATH, './/span[contains(@class,"zg-bdg-text")]'
            ).text.strip()
            rank = int(re.sub(r"\D", "", rank_text))
            logging.info(f"    ë­í¬: {rank_text} â†’ {rank}")
        except (NoSuchElementException, ValueError, StaleElementReferenceException) as e:
            logging.warning(f"    [{idx}] ë­í¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            continue

        # ì œëª©
        try:
            title = card.find_element(
                By.XPATH, './/div[contains(@class,"_cDEzb_p13n-sc-css-line-clamp-2_EWgCb")]'
            ).text.strip()
        except NoSuchElementException:
            title = card.find_element(By.XPATH, './/img[@alt]').get_attribute("alt").strip()
        logging.info(f"    ì œëª©: {title}")

        # LG í•„í„°
        title_norm = title.replace("\u00a0", " ").replace("\u202f", " ")
        if not re.search(r"\bLG\b", title_norm, re.I):
            logging.info(f"    LG ëª¨ë‹ˆí„° ì•„ë‹˜ â€“ ìŠ¤í‚µ: {title}")
            continue

        # ê°€ê²© (ë¬¸ìì—´ ê·¸ëŒ€ë¡œ)
        try:
            price = card.find_element(
                By.CSS_SELECTOR, 'span._cDEzb_p13n-sc-price_3mJ9Z'
            ).text.strip()
        except NoSuchElementException:
            price = ""
        logging.info(f"    ê°€ê²©: '{price}'")

        # ë§í¬ & ASIN
        try:
            href = card.find_element(
                By.XPATH, './/a[contains(@href,"/dp/")]'
            ).get_attribute("href")
            link = href.split("?", 1)[0]
            asin = re.search(r"/dp/([A-Z0-9]{10})", link).group(1)
            logging.info(f"    ë§í¬: {link}, ASIN: {asin}")
        except Exception as e:
            logging.warning(f"    [{idx}] ë§í¬/ASIN ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            continue

        parsed_items.append({
            "asin":  asin,
            "title": title,
            "url":   link,
            "price": price,
            "rank":  rank,
        })
        logging.info(f"  âœ” ì¹´ë“œ [{idx}] íŒŒì‹± ì„±ê³µ â€“ ASIN: {asin}, ë­í¬: {rank}, ê°€ê²©: {price}")

    return parsed_items

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. í¬ë¡¤ëŸ¬ ì‹¤í–‰ & ë¡œê·¸ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
driver = get_driver()
try:
    # --- 1) ë¡œê·¸ì¸ í˜ì´ì§€ ì´ë™ ---
    driver.get("https://www.amazon.de/-/en/ap/signin?openid.pape.max_auth_age=0&openid.return_to=https%3A%2F%2Fwww.amazon.de%2Fref%3Dnav_signin&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=deflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0")
    wait = WebDriverWait(driver, 20)

    # --- 2) ì•„ì´ë”” ì…ë ¥ & ë‹¤ìŒ ---
    amz_user = os.environ["AMZ_USER"]
    amz_pass = os.environ["AMZ_PASS"]
    wait.until(EC.presence_of_element_located((By.ID, "ap_email"))).send_keys(amz_user)
    wait.until(EC.element_to_be_clickable((By.ID, "continue"))).click()

    # --- 3) ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ & ë¡œê·¸ì¸ ---
    wait.until(EC.presence_of_element_located((By.ID, "ap_password"))).send_keys(amz_pass)
    wait.until(EC.element_to_be_clickable((By.ID, "signInSubmit"))).click()
    logging.info("ğŸ” ë¡œê·¸ì¸ ì™„ë£Œ (%s)", amz_user)

    # 2) í˜ì´ì§€ë³„ í¬ë¡¤ë§
    items = []
    for pg in (1, 2):
        try:
            items += fetch_cards_and_parse(pg, driver)
        except TimeoutException:
            logging.error(f"â›” í˜ì´ì§€ {pg} ì¹´ë“œ ë¡œë”© íƒ€ì„ì•„ì›ƒ ë°œìƒ")
finally:
    driver.quit()
    logging.info("ğŸ›‘ WebDriver ì¢…ë£Œ")

logging.info(f"ì´ íŒŒì‹±ëœ LG ëª¨ë‹ˆí„° ê°œìˆ˜: {len(items)}ê°œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. DataFrame ìƒì„± ë° í›„ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cols = ["asin", "title", "url", "price", "rank"]
df_today = pd.DataFrame(items, columns=cols)
logging.info(f"DataFrame ìƒì„±: {df_today.shape[0]}í–‰, {df_today.shape[1]}ì—´")

if df_today.empty:
    logging.info("LG ëª¨ë‹ˆí„° ì—†ìŒ â†’ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ìƒëµ")
    sys.exit(0)

# ì •ë ¬ ë° ë‚ ì§œ ì¶”ê°€
logging.info("DataFrame ì •ë ¬ ë° ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€")
df_today = df_today.sort_values("rank").reset_index(drop=True)
kst = pytz.timezone("Asia/Seoul")
df_today["date"] = datetime.datetime.now(kst).strftime("%Y-%m-%d %H:%M:%S")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Google Sheets ì—…ë°ì´íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.info("Google Sheets ì¸ì¦ ë° ì‹œíŠ¸ ì„ íƒ")
creds = Credentials.from_service_account_info(
    json.loads(base64.b64decode(os.environ["GCP_SA_BASE64"]).decode()),
    scopes=["https://www.googleapis.com/auth/spreadsheets"],
)
gc = gspread.authorize(creds)
sh = gc.open_by_key(os.environ["SHEET_ID"])

ws_hist = (
    sh.worksheet("History") if "History" in [w.title for w in sh.worksheets()]
    else sh.add_worksheet("History", rows=2000, cols=20)
)
ws_today = (
    sh.worksheet("Today") if "Today" in [w.title for w in sh.worksheets()]
    else sh.add_worksheet("Today", rows=100, cols=20)
)

cols_out = ["asin", "title", "rank", "price", "url", "date"]
logging.info(f"ì‹œíŠ¸ì— ê¸°ë¡í•  ì»¬ëŸ¼: {cols_out}")

df_to_write = df_today[cols_out].fillna("")

logging.info("History ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€")
ws_hist.append_rows(df_to_write.values.tolist(), value_input_option="USER_ENTERED")
logging.info("Today ì‹œíŠ¸ ì´ˆê¸°í™” ë° ë°ì´í„° ì“°ê¸°")
ws_today.clear()
ws_today.update([cols_out] + df_to_write.values.tolist(), value_input_option="USER_ENTERED")

logging.info("Google Sheets ì—…ë°ì´íŠ¸ ì™„ë£Œ")
print(f"âœ“ Google Sheet ì—…ë°ì´íŠ¸ ì™„ë£Œ â€” LG ëª¨ë‹ˆí„° {len(df_to_write)}ê°œ")
